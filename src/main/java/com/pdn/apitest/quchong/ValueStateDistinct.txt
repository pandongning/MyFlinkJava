package com.pdn.quchong;

import com.pdn.utils.ExecutionEnvironmentUtils;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.RichFlatMapFunction;
import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.api.common.state.MapStateDescriptor;
import org.apache.flink.api.common.state.StateTtlConfig;
import org.apache.flink.api.common.state.ValueState;
import org.apache.flink.api.common.state.ValueStateDescriptor;
import org.apache.flink.api.common.time.Time;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.connector.kafka.source.KafkaSource;
import org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.KeyedStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.util.Collector;

/**
 * @author pdn
 */
public class ValueStateDistinct {
    public static void main(String[] args) throws Exception {

        StreamExecutionEnvironment env = ExecutionEnvironmentUtils.getExecutionEnvironment();
        env.setParallelism(3);

        KafkaSource<String> source = KafkaSource.<String>builder()
//                因为本地配置了端口的映射，所以此处用于本地测试
                .setBootstrapServers("127.0.0.1:9094")
//                集群环境的配置
//                .setBootstrapServers("slave1:9094,slave2:9092,master:9093")
                .setTopics("a")
                .setGroupId("my-group-a")
                .setStartingOffsets(OffsetsInitializer.latest())
                .setValueOnlyDeserializer(new SimpleStringSchema())
                .build();

        DataStreamSource<String> streamSource = env.fromSource(source, WatermarkStrategy.noWatermarks(), "a");
        SingleOutputStreamOperator<Tuple2<String, String>> map = streamSource.map(x -> new Tuple2<String, String>(x.split(",")[0], x.split(",")[1]))
                .returns(Types.TUPLE(Types.STRING,Types.STRING));

//        下面必须进行keyBy。因为去重是根据key进行去重的，
        KeyedStream<Tuple2<String, String>, String> keyedStream = map.keyBy(x -> x.f0);

        SingleOutputStreamOperator<String> quchong = keyedStream.flatMap(new RichFlatMapFunction<Tuple2<String, String>, String>() {
            ValueState<Boolean> keyHasBeenSeen;

            //           每个算字都会执行一次，比如并行度为3，则此时会执行3次
            @Override
            public void open(Configuration parameters) throws Exception {
                System.out.println("我又执行一次呢");
                super.open(parameters);
                StateTtlConfig build = StateTtlConfig.newBuilder(Time.seconds(5))
                        .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
                        .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
                        .build();
                ValueStateDescriptor<Boolean> hasBeenSeen = new ValueStateDescriptor<>("keyHasBeenSeen", Boolean.class);
                keyHasBeenSeen = getRuntimeContext().getState(hasBeenSeen);

            }

            @Override
            public void flatMap(Tuple2<String, String> value, Collector<String> out) throws Exception {
                if (keyHasBeenSeen.value() == null) {
                    out.collect(value.f0+"$$"+value.f1);
                    keyHasBeenSeen.update(true);
                }

            }
        }).returns(Types.STRING);


        quchong.print("quchong");


        env.execute("KafkaConnector");
    }
}
